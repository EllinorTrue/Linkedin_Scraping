"""
Created on Tue Oct 12 12:37:39 2021

@author: ellinorsaltin
"""

from bs4 import BeautifulSoup
from selenium import webdriver
import csv

class GetInfo:
    def __init__(self, file):
        self.pages = self.get_names(file)
        self.error_pages = []

        self.browser = webdriver.Chrome('/usr/local/bin/chromedriver2')
        self.browser.get('https://www.linkedin.com/uas/login')

        ''' login to Linkedin'''

        file = open('/Users/ellinorsaltin/Desktop/linkedin.txt')
        lines = file.readlines()
        username = lines[0]
        password = lines[1]

        elementID = self.browser.find_element_by_id('username')
        elementID.send_keys(username)

        elementID = self.browser.find_element_by_id('password')
        elementID.send_keys(password)

        elementID.submit()
        self.page()
        print(self.error_pages)
        
        
    '''Get names from MASTER sheet '''

    def get_names(self, file):
        names = []
        with open(file, 'r') as f:
            for i in f.readlines():
                name = ''
                for j in i:
                    if j != ',' and j != '.':
                        if j == ' ':
                            name = name + '-'
                        else:
                            name = name + j
                    else:
                        if name:
                            names.append('/company/' + name + '/insights/')
                        break
        return names

    ''' a Function to visit the company insights page '''
    def get_page(self, visiting_profile_id):
        try:
            full_link = 'https://www.linkedin.com/' + visiting_profile_id
            self.browser.get(full_link)
            src = self.browser.page_source
            soup = BeautifulSoup(src, 'lxml')

            name_div = soup.find('div', {'class': 'block mt2'})
            name = name_div.find('span').get_text().strip()
            
            return True
        except:
            return False
        
    ''' Testing names for urls cause i was too lazy to pull the actual urls '''

    def get_right_page(self, visiting_profile_id):
        if self.get_page(visiting_profile_id):
            return True

        if visiting_profile_id.__contains__('-'):
            name = ''
            for i in visiting_profile_id:
                if i != '-':
                    name = name + i

            if self.get_page(name):
                return True
            else:
                name = ''
                for i in visiting_profile_id:
                    if i == '-':
                        break

                    name = name + i

                if self.get_page(name):
                    return True

        name = ''
        for i in visiting_profile_id:
            if i.isupper():
                name = name + i

        if self.get_page(name):
            return True
        else:
            return False

    ''' Scraping the information that we want '''

    def page(self):
        for visiting_profile_id in self.pages:
            errors = []

            ''' visit a page '''
            if self.get_right_page(visiting_profile_id):
                src = self.browser.page_source
                soup = BeautifulSoup(src, 'lxml')

                ''' First card '''

                try:
                    name_div = soup.find('div', {'class': 'block mt2'})
                    try:
                        name = name_div.find('span').get_text().strip()
                    except:
                        name = None # these error thingimaginies are basically if python can't find it on the page and therefore ignores it
                        errors.append('name')

                    try:
                        tag = name_div.find('p').get_text().strip()
                    except:
                        tag = None
                        errors.append('tag')

                    try:
                        sector = name_div.find('div', {'class': 'org-top-card-summary-info-list__info-item'}).get_text().strip()
                    except:
                        sector = None
                        errors.append('sector')

                except:
                    name = None
                    tag = None
                    sector = None

                ''' Location '''

                try:
                    location = soup.find('div', {'class': 'inline-block'})
                    location = location.find('div').get_text().strip()
                except:
                    errors.append('location')
                    location = None

                ''' Second Card '''

                try:
                    Insights_div = soup.find('div', {'class': 'pt4 ph5 pb5'})
                    growth = Insights_div.find_all('span')

                    try:
                        six_month_growth = growth[1].find('span', {'class': 'visually-hidden'}).get_text().strip()  # 6 months
                    except:
                        errors.append('six_month_growth')
                        six_month_growth = None

                    try:
                        one_year_growth = growth[4].find('span', {'class': 'visually-hidden'}).get_text().strip()  # 1 year
                    except:
                        errors.append('one_year_growth')
                        one_year_growth = None

                    try:
                        two_year_growth = growth[7].find('span', {'class': 'visually-hidden'}).get_text().strip()  # 2 years
                    except:
                        errors.append('two_year_growth')
                        two_year_growth = None

                    try:
                        employees = growth[0].get_text().strip()
                    except:
                        errors.append('employees')
                        employees = None

                except:
                    errors.append('six_month_growth')
                    errors.append('one_year_growth')
                    errors.append('two_year_growth')
                    errors.append('employees')

                    six_month_growth = None
                    one_year_growth = None
                    two_year_growth = None
                    employees = None

                ''' All Variables '''
                
                
                Variables = [name, tag, sector, location, six_month_growth, one_year_growth, two_year_growth, employees] # creating a list with all of the variables

                ''' Saving all variables in a csv file which later can be opened in excel '''

                with open('linkedin_scrapecompany1.csv', 'a') as f:
                    object = csv.writer(f)
                    object.writerow(Variables)
                    f.close()

            else:
                errors_name = visiting_profile_id[9:]
                real_name = ''
                for i in errors_name:
                    if errors_name == '/':
                        break
                    else:
                        real_name = real_name + i
                
                if errors:
                    self.error_pages.append([real_name, errors])
                else:
                    self.error_pages.append(real_name)
                
                with open('linkedin_scrapecompany1.csv', 'a') as f:
                    object = csv.writer(f)
                    object.writerow([real_name])
                    f.close()
                    
                    
GetInfo('MASTER.csv')                    
                    
